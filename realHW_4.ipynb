{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import turicreate as tc\nimport turicreate.aggregate as agg","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"products = tc.SFrame('../input/basicml-lecture1/amazon_baby.sframe')\nproducts['word_count'] = tc.text_analytics.count_words(products['review'])","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_words = ['awesome', 'great', 'fantastic', 'amazing', 'love', 'horrible', 'bad', 'terrible', 'awful', 'wow', 'hate']","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(11):\n    word = selected_words[i]\n    products[word] = products.apply(lambda x: x['word_count'][word] if word in x['word_count'] else 0)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_num = 0\nmin_num = 999999\nfor i in range(11):\n    word = selected_words[i]\n    tmp = products[word].sum()\n    if tmp > max_num:\n        max_num = tmp\n        max_name = word\n    if tmp < min_num:\n        min_num = tmp\n        min_name = word\n        \nprint(\"The most used word is {}, It appears {} times\".format(max_name, max_num))\nprint(\"The least used word is {}, It appears {} times\".format(min_name, min_num))","execution_count":7,"outputs":[{"output_type":"stream","text":"The most used word is great, It appears 59536.0 times\nThe least used word is wow, It appears 461 times\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Question 1: [5]great\n### Question 2: [1]wow"},{"metadata":{"trusted":true},"cell_type":"code","source":"#ignore all 3* reviews\nproducts = products[products['rating']!= 3]\n#positive sentiment = 4-star or 5-star reviews\nproducts['sentiment'] = products['rating'] >= 4\n\ntrain_data,test_data = products.random_split(.8,seed=0)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_model = tc.logistic_classifier.create(train_data,target='sentiment', features=['word_count'], validation_set=test_data)","execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Logistic regression:","text/html":"<pre>Logistic regression:</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"--------------------------------------------------------","text/html":"<pre>--------------------------------------------------------</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Number of examples          : 133448","text/html":"<pre>Number of examples          : 133448</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Number of classes           : 2","text/html":"<pre>Number of classes           : 2</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Number of feature columns   : 1","text/html":"<pre>Number of feature columns   : 1</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Number of unpacked features : 57356","text/html":"<pre>Number of unpacked features : 57356</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Number of coefficients      : 57357","text/html":"<pre>Number of coefficients      : 57357</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Starting L-BFGS","text/html":"<pre>Starting L-BFGS</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"--------------------------------------------------------","text/html":"<pre>--------------------------------------------------------</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"+-----------+----------+-----------+--------------+-------------------+---------------------+","text/html":"<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy | Validation Accuracy |","text/html":"<pre>| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy | Validation Accuracy |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"+-----------+----------+-----------+--------------+-------------------+---------------------+","text/html":"<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 0         | 4        | 0.250000  | 1.934654     | 0.841421          | 0.840019            |","text/html":"<pre>| 0         | 4        | 0.250000  | 1.934654     | 0.841421          | 0.840019            |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 1         | 9        | 3.250000  | 3.265721     | 0.931359          | 0.911362            |","text/html":"<pre>| 1         | 9        | 3.250000  | 3.265721     | 0.931359          | 0.911362            |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 2         | 11       | 2.669978  | 3.952254     | 0.938650          | 0.916466            |","text/html":"<pre>| 2         | 11       | 2.669978  | 3.952254     | 0.938650          | 0.916466            |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 3         | 12       | 2.669978  | 4.370787     | 0.927417          | 0.901814            |","text/html":"<pre>| 3         | 12       | 2.669978  | 4.370787     | 0.927417          | 0.901814            |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 4         | 14       | 1.326072  | 5.000852     | 0.945200          | 0.918088            |","text/html":"<pre>| 4         | 14       | 1.326072  | 5.000852     | 0.945200          | 0.918088            |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 9         | 20       | 1.326072  | 7.360418     | 0.977654          | 0.917698            |","text/html":"<pre>| 9         | 20       | 1.326072  | 7.360418     | 0.977654          | 0.917698            |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"+-----------+----------+-----------+--------------+-------------------+---------------------+","text/html":"<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_words_model = tc.logistic_classifier.create(train_data,target='sentiment', features=selected_words, validation_set=test_data)","execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Logistic regression:","text/html":"<pre>Logistic regression:</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"--------------------------------------------------------","text/html":"<pre>--------------------------------------------------------</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Number of examples          : 133448","text/html":"<pre>Number of examples          : 133448</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Number of classes           : 2","text/html":"<pre>Number of classes           : 2</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Number of feature columns   : 11","text/html":"<pre>Number of feature columns   : 11</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Number of unpacked features : 11","text/html":"<pre>Number of unpacked features : 11</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Number of coefficients      : 12","text/html":"<pre>Number of coefficients      : 12</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Starting Newton Method","text/html":"<pre>Starting Newton Method</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"--------------------------------------------------------","text/html":"<pre>--------------------------------------------------------</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"+-----------+----------+--------------+-------------------+---------------------+","text/html":"<pre>+-----------+----------+--------------+-------------------+---------------------+</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| Iteration | Passes   | Elapsed Time | Training Accuracy | Validation Accuracy |","text/html":"<pre>| Iteration | Passes   | Elapsed Time | Training Accuracy | Validation Accuracy |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"+-----------+----------+--------------+-------------------+---------------------+","text/html":"<pre>+-----------+----------+--------------+-------------------+---------------------+</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 1         | 2        | 0.172135     | 0.847401          | 0.845874            |","text/html":"<pre>| 1         | 2        | 0.172135     | 0.847401          | 0.845874            |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 2         | 3        | 0.295725     | 0.847514          | 0.846085            |","text/html":"<pre>| 2         | 3        | 0.295725     | 0.847514          | 0.846085            |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 3         | 4        | 0.409910     | 0.847626          | 0.846115            |","text/html":"<pre>| 3         | 4        | 0.409910     | 0.847626          | 0.846115            |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 4         | 5        | 0.525289     | 0.847708          | 0.846385            |","text/html":"<pre>| 4         | 5        | 0.525289     | 0.847708          | 0.846385            |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 5         | 6        | 0.641875     | 0.847708          | 0.846385            |","text/html":"<pre>| 5         | 6        | 0.641875     | 0.847708          | 0.846385            |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 6         | 7        | 0.761048     | 0.847708          | 0.846385            |","text/html":"<pre>| 6         | 7        | 0.761048     | 0.847708          | 0.846385            |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"+-----------+----------+--------------+-------------------+---------------------+","text/html":"<pre>+-----------+----------+--------------+-------------------+---------------------+</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"SUCCESS: Optimal solution found.","text/html":"<pre>SUCCESS: Optimal solution found.</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre></pre>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"weight = selected_words_model.coefficients.sort('value')\nprint(\"The word with the most positive weight is {}: {}\".format(weight[-1]['name'], weight[-1]['value']))\nprint(\"The word with the most negative weight is {}: {}\".format(weight[0]['name'], weight[0]['value']))","execution_count":10,"outputs":[{"output_type":"stream","text":"The word with the most positive weight is love: 1.359268866922504\nThe word with the most negative weight is horrible: -2.251335236759102\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Question 3: The most positive weight: [3]love\n### Question 4: THe most negative weight: [1]horrible"},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_words_model.evaluate(test_data)['accuracy']","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"0.8463848186404036"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_model.evaluate(test_data)['accuracy']","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"0.9176975738650012"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Question 5: selected_words_model: [2]0.841 to 0.871\n### Question 6: sentiment_model: [4]0.901 to 0.931"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.groupby('sentiment', operations={'sum': agg.COUNT()})","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"Columns:\n\tsentiment\tint\n\tsum\tint\n\nRows: 2\n\nData:\n+-----------+-------+\n| sentiment |  sum  |\n+-----------+-------+\n|     0     |  5328 |\n|     1     | 27976 |\n+-----------+-------+\n[2 rows x 2 columns]","text/html":"<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n    <tr>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sentiment</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sum</th>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5328</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">27976</td>\n    </tr>\n</table>\n[2 rows x 2 columns]<br/>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy of majority class classifier: {:.2f}\".format(27976/(27976+5328)))","execution_count":16,"outputs":[{"output_type":"stream","text":"Accuracy of majority class classifier: 0.84\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Question 7: majority class classifier: [1]0.811 to 0.843\n### Question 8: [3]The model learned using all words performed much better than the two. The other two approaches performed about the same."},{"metadata":{"trusted":true},"cell_type":"code","source":"diaper_champ_reviews = products[products['name'] == 'Baby Trend Diaper Champ']\ndiaper_champ_reviews['predicted_sentiment'] = sentiment_model.predict(diaper_champ_reviews, output_type = 'probability')\nsorted_reviews = diaper_champ_reviews.sort('predicted_sentiment', False)\nprint('The most positive: {} '.format(sorted_reviews[0]['predicted_sentiment']))","execution_count":17,"outputs":[{"output_type":"stream","text":"The most positive: 0.9999999999895941 \n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Question 9: [4]0.9 to 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_word_result = sorted_reviews[0:1]\nselected_word_result['predicted_sentiment'] = selected_words_model.predict(selected_word_result, output_type = 'probability')\nprint('The result in predicted_words_model : {} '.format(selected_word_result[0]['predicted_sentiment']))","execution_count":18,"outputs":[{"output_type":"stream","text":"The result in predicted_words_model : 0.7919288370624482 \n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Quesion 10: [2]0.7 to 0.8"},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_word_result","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"Columns:\n\tname\tstr\n\treview\tstr\n\trating\tfloat\n\tword_count\tdict\n\tawesome\tint\n\tgreat\tfloat\n\tfantastic\tfloat\n\tamazing\tint\n\tlove\tfloat\n\thorrible\tint\n\tbad\tint\n\tterrible\tint\n\tawful\tint\n\twow\tint\n\thate\tint\n\tsentiment\tint\n\tpredicted_sentiment\tfloat\n\nRows: 1\n\nData:\n+-------------------------+-------------------------------+--------+\n|           name          |             review            | rating |\n+-------------------------+-------------------------------+--------+\n| Baby Trend Diaper Champ | I read a review below that... |  4.0   |\n+-------------------------+-------------------------------+--------+\n+-------------------------------+---------+-------+-----------+---------+------+\n|           word_count          | awesome | great | fantastic | amazing | love |\n+-------------------------------+---------+-------+-----------+---------+------+\n| {'key': 1.0, 'have': 1.0, ... |    0    |  0.0  |    0.0    |    0    | 0.0  |\n+-------------------------------+---------+-------+-----------+---------+------+\n+----------+-----+----------+-------+-----+------+-----------+\n| horrible | bad | terrible | awful | wow | hate | sentiment |\n+----------+-----+----------+-------+-----+------+-----------+\n|    0     |  0  |    0     |   0   |  0  |  0   |     1     |\n+----------+-----+----------+-------+-----+------+-----------+\n+---------------------+\n| predicted_sentiment |\n+---------------------+\n|  0.7919288370624482 |\n+---------------------+\n[1 rows x 17 columns]","text/html":"<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n    <tr>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">review</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">rating</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">word_count</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">awesome</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">great</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">fantastic</th>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Baby Trend Diaper Champ</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">I read a review below<br>that can explain exactly ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;key&#x27;: 1.0, &#x27;have&#x27;: 1.0,<br>&#x27;pieces&#x27;: 1.0, &#x27;betwe ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n    </tr>\n</table>\n<table frame=\"box\" rules=\"cols\">\n    <tr>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">amazing</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">love</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">horrible</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">bad</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">terrible</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">awful</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">wow</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">hate</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sentiment</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">predicted_sentiment</th>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.7919288370624482</td>\n    </tr>\n</table>\n[1 rows x 17 columns]<br/>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Question 11: [4]None of the selected words appeared in the text of this review.\nAs you can see, the columns of the selected words are all 0."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}